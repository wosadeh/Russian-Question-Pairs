@article{shavrina2020russiansuperglue,
    title={RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark},
    author={Shavrina, Tatiana and Fenogenova, Alena and Emelyanov, Anton and Shevelev, Denis and Artemova, Ekaterina and Malykh, Valentin and Mikhailov, Vladislav and Tikhonova, Maria and Chertok, Andrey and Evlampiev, Andrey},
    journal={arXiv preprint arXiv:2010.15925},
    year={2020}
}
@article{wang2019superglue,
    title={Superglue: A stickier benchmark for general-purpose language understanding systems},
    author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
    journal={arXiv preprint arXiv:1905.00537},
    year={2019}
}
@article{wang2018glue,
    title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
    author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
    journal={arXiv preprint arXiv:1804.07461},
    year={2018}
}
@inproceedings{ganitkevitch2013ppdb,
    title={PPDB: The paraphrase database},
    author={Ganitkevitch, Juri and Van Durme, Benjamin and Callison-Burch, Chris},
    booktitle={Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
    pages={758--764},
    year={2013}
}
@inproceedings{pavlick2015ppdb,
    title={PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification},
    author={Pavlick, Ellie and Rastogi, Pushpendre and Ganitkevitch, Juri and Van Durme, Benjamin and Callison-Burch, Chris},
    booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
    pages={425--430},
    year={2015}
}
@article{wieting2017paranmt,
    title={ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations},
    author={Wieting, John and Gimpel, Kevin},
    journal={arXiv preprint arXiv:1711.05732},
    year={2017}
}
@inproceedings{pivovarova2017paraphraser,
    title={ParaPhraser: Russian paraphrase corpus and shared task},
    author={Pivovarova, Lidia and Pronoza, Ekaterina and Yagunova, Elena and Pronoza, Anton},
    booktitle={Conference on Artificial Intelligence and Natural Language},
    pages={211--225},
    year={2017},
    organization={Springer}
}
@online{iyer_csernai_dandekar_2017,
    title={First Quora Dataset Release: Question Pairs - Data @ Quora}, url={https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs},
    journal={Quora},
    author={Iyer, Shankar and Csernai, Kornél and Dandekar, Nikhil},
    year={2017},
    month={Jan},
    urldate={2021-02-01}
} 
@inproceedings{lan-etal-2017-continuously,
    title = {A Continuously Growing Dataset of Sentential Paraphrases},
    author = {Lan, Wuwei  and
    Qiu, Siyu  and
    He, Hua  and
    Xu, Wei},
    booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
    month = {Sep},
    year = {2017},
    address = {Copenhagen, Denmark},
    publisher = {Association for Computational Linguistics},
    url = {https://www.aclweb.org/anthology/D17-1126},
    doi = {10.18653/v1/D17-1126},
    pages = {1224--1234},
    abstract = {A major challenge in paraphrase research is the lack of parallel corpora. In this paper, we present a new method to collect large-scale sentential paraphrases from Twitter by linking tweets through shared URLs. The main advantage of our method is its simplicity, as it gets rid of the classifier or human in the loop needed to select data before annotation and subsequent application of paraphrase identification algorithms in the previous work. We present the largest human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification. In addition, we show that more than 30,000 new sentential paraphrases can be easily and continuously captured every month at {\textasciitilde}70{\%} precision, and demonstrate their utility for downstream NLP tasks through phrasal paraphrase extraction. We make our code and data freely available.},
}
@article{zhang2019paws,
    title={PAWS: Paraphrase adversaries from word scrambling},
    author={Zhang, Yuan and Baldridge, Jason and He, Luheng},
    journal={arXiv preprint arXiv:1904.01130},
    year={2019}
}
@article{ляшевская2009новый,
    title={Новый частотный словарь русской лексики},
    author={Ляшевская, ОН and Шаров, СА},
    journal={М.: Азбуковник},
    year={2009},
    url={http://dict.ruslang.ru/freq.php}
}
@book{ляшевская2009частотный,
    title={Частотный словарь современного русского языка: на материалах Национального корпуса русского языка},
    author={Ляшевская, Ольга Николаевна and Шаров, Сергей Александрович},
    year={2009},
    publisher={Азбуковник}
}
@online{scrapy_docs,
     title={Scrapy 2.4 documentation}, url={https://docs.scrapy.org/en/2.4/},
     year={2020},
     month={Oct},
     urldate={2021-02-01}
} 
@article{reimers2019sentence,
    title={Sentence-bert: Sentence embeddings using siamese bert-networks},
    author={Reimers, Nils and Gurevych, Iryna},
    journal={arXiv preprint arXiv:1908.10084},
    year={2019}
}
@article{devlin2018bert,
    title={Bert: Pre-training of deep bidirectional transformers for language understanding},
    author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    journal={arXiv preprint arXiv:1810.04805},
    year={2018}
}
@online{yandex_legal,
    title={Условия использования сервиса Яндекс.Кью}, url={https://yandex.ru/legal/q_termsofuse/},
    journal={Yandex},
    year={2019},
    month={Dec},
    urldate={2020-12-26}
}
@online{mail_legal,
    title={Пользовательское соглашение "Ответы Mail.ru"}, url={https://help.mail.ru/legal/terms/answers/ua},
    journal={Mail.ru},
    year={2018},
    month={Nov},
    urldate={2020-12-26}
}
@article{dawid1979maximum,
    title={Maximum likelihood estimation of observer error-rates using the EM algorithm},
    author={Dawid, Alexander Philip and Skene, Allan M},
    journal={Journal of the Royal Statistical Society: Series C (Applied Statistics)},
    volume={28},
    number={1},
    pages={20--28},
    year={1979},
    publisher={Wiley Online Library}
}
@incollection{pymorphy2,
    year={2015},
    isbn={978-3-319-26122-5},
    booktitle={Analysis of Images, Social Networks and Texts},
    volume={542},
    series={Communications in Computer and Information Science},
    editor={Khachay, Mikhail Yu. and Konstantinova, Natalia and Panchenko, Alexander and Ignatov, Dmitry I. and Labunets, Valeri G.},
    doi={10.1007/978-3-319-26123-2_31},
    title={Morphological Analyzer and Generator for Russian and Ukrainian Languages},
    url={http://dx.doi.org/10.1007/978-3-319-26123-2_31},
    publisher={Springer International Publishing},
    keywords={Morphological analyzer; Russian; Ukrainian; Morphological generator; Open source; OpenCorpora; LanguageTool; pymorphy2; pymorphy},
    author={Korobov, Mikhail},
    pages={320-332},
    language={English}
}
@article{mccarthy2010mtld,
    title={MTLD, vocd-D, and HD-D: A validation study of sophisticated approaches to lexical diversity assessment},
    author={McCarthy, Philip M and Jarvis, Scott},
    journal={Behavior research methods},
    volume={42},
    number={2},
    pages={381--392},
    year={2010},
    publisher={Springer}
}
@article{fleiss1971measuring,
    title={Measuring nominal scale agreement among many raters.},
    author={Fleiss, Joseph L},
    journal={Psychological bulletin},
    volume={76},
    number={5},
    pages={378},
    year={1971},
    publisher={American Psychological Association}
}
@article{kuratov2019adaptation,
    title={Adaptation of deep bidirectional multilingual transformers for russian language},
    author={Kuratov, Yuri and Arkhipov, Mikhail},
    journal={arXiv preprint arXiv:1905.07213},
    year={2019}
}
@article{kingma2014adam,
    title={Adam: A method for stochastic optimization},
    author={Kingma, Diederik P and Ba, Jimmy},
    journal={arXiv preprint arXiv:1412.6980},
    year={2014}
}
@article{ng2019facebook,
    title={Facebook FAIR's WMT19 News Translation Task Submission},
    author={Ng, Nathan and Yee, Kyra and Baevski, Alexei and Ott, Myle and Auli, Michael and Edunov, Sergey},
    journal={arXiv preprint arXiv:1907.06616},
    year={2019}
}
@inproceedings{wmt19findings,
    title={Findings of the 2019 conference on machine translation (wmt19)},
    author={Barrault, Lo{\"\i}c and Bojar, Ond{\v{r}}ej and Costa-Jussa, Marta R and Federmann, Christian and Fishel, Mark and Graham, Yvette and Haddow, Barry and Huck, Matthias and Koehn, Philipp and Malmasi, Shervin and others},
    booktitle={Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)},
    pages={1--61},
    year={2019}
}
@article{feng2020language,
    title={Language-agnostic bert sentence embedding},
    author={Feng, Fangxiaoyu and Yang, Yinfei and Cer, Daniel and Arivazhagan, Naveen and Wang, Wei},
    journal={arXiv preprint arXiv:2007.01852},
    year={2020}
}
@article{vaswani2017attention,
    title={Attention is all you need},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
    journal={arXiv preprint arXiv:1706.03762},
    year={2017}
}
@online{deeppavlov_sbert,
    title={DeepPavlov/rubert-base-cased-sentence}, url={https://huggingface.co/DeepPavlov/rubert-base-cased-sentence},
    year={2020},
    month={Dec},
    urldate={2021-02-01}
} 
