\documentclass[a4paper,14pt]{extarticle}
\usepackage{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{indentfirst}
\usepackage[colorlinks,citecolor=blue,linkcolor=blue,bookmarks=false,hypertexnames=true, urlcolor=blue]{hyperref} 
\usepackage{indentfirst}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage[flushleft]{threeparttable}
\usepackage{tablefootnote}
\usepackage{diagbox}
\usepackage{csquotes}
\usepackage{comment}

\usepackage{makecell}

\usepackage{chngcntr} % нумерация графиков и таблиц по секциям
\counterwithin{table}{section}
\counterwithin{figure}{section}

% \graphicspath{{graphics/}}%путь к рисункам

\makeatletter
% \renewcommand{\@biblabel}[1]{#1.} % Заменяем библиографию с квадратных скобок на точку:
\makeatother

\geometry{left=2.5cm}% левое поле
\geometry{right=1.5cm}% правое поле
\geometry{top=1.5cm}% верхнее поле
\geometry{bottom=1.5cm}% нижнее поле
\renewcommand{\baselinestretch}{1.5} % междустрочный интервал


% \newcommand{\bibref}[3]{\hyperlink{#1}{#2 (#3)}} % biblabel, authors, year
% \addto\captionsrussian{\def\refname{Список литературы (или источников)}} 

\renewcommand{\theenumi}{\arabic{enumi}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumi}{\arabic{enumi}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\theenumii}{.\arabic{enumii}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}.}% Меняем везде перечисления на цифра.цифра
\renewcommand{\theenumiii}{.\arabic{enumiii}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumiii}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.}% Меняем везде перечисления на цифра.цифра

% Подключаем BibLaTex
\usepackage[%
backend=biber,% движок
bibencoding=utf8,% кодировка bib файла
sorting=ntvy,
% sorting=none,% настройка сортировки списка литературы
style=gost-numeric,% стиль цитирования и библиографии (по ГОСТ)
language=autobib,% получение языка из babel/polyglossia, default: autobib % если ставить autocite или auto, то цитаты в тексте с указанием страницы, получат указание страницы на языке оригинала
autolang=other,% многоязычная библиография
clearlang=true,% внутренний сброс поля language, если он совпадает с языком из babel/polyglossia
sortcites=true,% сортировать номера затекстовых ссылок при цитировании (если в квадратных скобках несколько ссылок, то отображаться будут отсортированно, а не абы как)
doi=false,% Показывать или нет ссылки на DOI
isbn=false,% Показывать или нет ISBN, ISSN, ISRN
movenames=false, % Не заменяем авторов названием, если у публикации более 3 авторов
maxnames=10, % Исправляет сокращение [и др.] в библиографии
]{biblatex}
\appto{\bibsetup}{\raggedright}
\bibliography{sources}

\newcommand{\nocontentsline}[3]{}
\newcommand{\tocless}[2]{\bgroup\let\addcontentsline=\nocontentsline#1{#2}\egroup}

\addto\captionsrussian{\renewcommand{\contentsname}{Оглавление}}
\begin{document}
\input{title.tex}% титульный лист
\newpage

{
	\hypersetup{linkcolor=black}
	\tableofcontents
}

\newpage
\addcontentsline{toc}{section}{Аннотация}
\begin{abstract}
    В последние несколько лет предварительно обученные нейросетевые языковые модели находят все большее применение в различных задачах обработки естественного языка.
    Для оценки и сравнения таких моделей на русском языке активно разрабатывается бенчмарк RussianSuperGLUE.
    На данный момент он содержит меньшее число заданий, чем аналоги на английском языке.
    В рамках данной работы был разработан набор данных на русском языке, который позволяет оценивать качество решения задачи обнаружения парафраза.
\end{abstract}
\textbf{\textit{Ключевые слова---}} Обнаружение парафраза, обработка естественного языка, GLUE, разработка датасета, QQP, перенос обучения
    
\selectlanguage{english}
\begin{abstract}
    In the past few years, pretrained neural language models have found broad application in various natural language processing tasks.
    RussianSuperGLUE is an actively developed benchmark for evaluating and comparing such Russian-language models.
    Nevertheless, he is currently inferior to counterpart in English in the number of tasks.
    The paper introduces a question pairs dataset in Russian that can be used to evaluate the quality of the paraphrase detection model.
\end{abstract}

\selectlanguage{russian}
\section{Введение}
\subsection{Описание предметной области}
Бенчмарк в контексте машинного обучения — набор заданий, позволяющих оценить качество модели.
Каждое задание соответствует конкретной задаче машинного обучения и представлено выборкой данных, характерных для данной задачи.
В задании обязательно присутствует недоступная во время обучения тестовая выборка, на которой и измеряется качество ответов модели с помощью заранее определенных метрик качества.
Обычно задание также содержит обучающую выборку.
Однако в процессе обучения многих моделей зачастую используются дополнительные данные.

Для задач обработки текстов на английском языке существует большое количество бенчмарков.
\mbox{GLUE}~\autocite{wang2018glue} содержит набор заданий, которые позволяют оценить общее понимание естественного языка моделью.
Данная оценка наиболее актуальна для современных моделей на основе архитектуры <<Трансформер>>~\autocite{vaswani2017attention}, которые демонстрируют впечатляющие результаты во многих задачах обработки естественного языка.

Более того, качество решения предложенных задач новейшими языковыми моделями вплотную приближается или даже превосходит результат, демонстрируемый человеком.
Бенчмарк \mbox{SuperGLUE}~\autocite{wang2019superglue} предлагает набор более сложных и разнообразных заданий.

Аналогичный подход к оценке качества языковых моделей для русского языка реализует бенчмарк \mbox{RussianSuperGLUE}~\autocite{shavrina2020russiansuperglue}.
На данный момент в нем отсутствуют многие задания, представленные в англоязычных аналогах.

Одной из таких задач является обнаружение парафраза — пары различных предложений, совпадающих по смыслу.
Для оценки качества определения парафраза на английском языке наибольшую популярность получил набор данных \mbox{<<Quora Question Pairs>>} (\mbox{<<QQP>>})~\autocite{iyer_csernai_dandekar_2017}.
Он состоит из пар коротких вопросов. Каждой паре сопоставлена бинарная метка, показывающая повторяют ли вопросы друг-друга по смыслу.

\subsection{Постановка задачи}
В работе была поставлена задача создания набора данных, аналога \mbox{<<QQP>>} на русском языке, применимого для оценки качества обнаружения парафраза предварительно обученными языковыми моделями.
Набор должен состоять из пар коротких вопросов.
Каждой паре необходимо сопоставить бинарную метку, показывающую является ли она парафразом.
Разметка должна быть произведена полностью вручную с помощью краудсорнинговой платформы.

\section{Обзор литературы}
Задача обнаружения парафраза между парой документов является распространенной задачей анализа естественного языка.
Как следствие существуют несколько наборов данных, состоящих из пар семантически близких документов, различающихся по размеру, специфике текстов и подходу к сбору и разметке данных.

Наиболее объемные наборы получены с помощью автоматического составления парафразов.
Авторы набора \mbox{<<PPDB>>}~\autocite{ganitkevitch2013ppdb} представили корпус из $230$ миллионов пар на английском языке, полученный с использованием моделей семантической близости предложений.
Набор \mbox{<<ParaNMT>>}~\autocite{wieting2017paranmt} из $50$ миллионов пар был создан из параллельного корпуса текстов на английском и чешском языках с помощью предварительно обученной нейросетевой модели машинного перевода текстов.
Хотя процесс автоматической разметки данных может приводить к появлению ошибок в полученных парах, авторы демонстрируют, что полученные наборы могут успешно применяться для обучения моделей обнаружения парафразов.

Однако подобные наборы данных не подходят для оценки качества языковых моделей, так как они могут содержать значительное число неточно размеченных пар.
Как следствие значение метрик качества, вычисленное на основе подобных выборок, не будет отражать реальное качество модели.
Поэтому для оценки и сравнения моделей выявления парафраза обычно используют вручную размеченные данные.
Наиболее популярным является корпус \mbox{<<QQP>>}~\autocite{iyer_csernai_dandekar_2017}, составленный из пар вопросов, опубликованных пользователями сайта \href{https://www.quora.com/}{\mbox{Quora.com}}, и размеченный вручную.
Несмотря на то, что авторы не публикуют подробную методику составления корпуса и признают возможность наличия ошибок в нем, этот набор данных успешно применяется для оценки качества моделей.

При комбинировании техник ручной разметки и автоматической генерации итоговый корпус получается значительно большего размера в сравнении с наборами, размеченными исключительно вручную, и содержит меньше ошибок, чем наборы данных, составленные полностью автоматически.
Составители набора \mbox{<<Language-Net>>}~\autocite{lan-etal-2017-continuously} демонстрируют, что модель, обученная на вручную размеченном наборе данных, позволяет в дальнейшем непрерывно отбирать новые пары-кандидаты с точностью близкой к $70\%$.

В другой работе~\autocite{zhang2019paws} был предложен подход к расширению существующего корпуса парафразов за счет генерирования новых пар, полученных путем перестановки слов в исходных предложениях.
Авторами был сделан вывод о невысокой точности данного способа из-за чувствительности предложений на английском языке к изменению порядка слов.
Однако данный подход может оказаться более эффективным при применении к корпусу на русском языке, в котором перестановка слов менее выражено изменяет смысл предложения.

Один из немногих корпусов парафраза на русском языке \mbox{<<Paraphraser>>}~\autocite{pivovarova2017paraphraser} является полностью размеченным вручную. Предложения в корпусе получены из заголовков публикаций российских новостных агентств.
Для отбора пар-кандидатов авторы используют собственную метрику близости предложений, что позволяет повысить эффективность дальнейшей ручной обработки.
В отличие от ранее рассмотренных, в представленном наборе данных пары делятся на три класса: полностью совпадающие по смыслу ($1$), близкие по смыслу ($0$) и разные по смыслу ($-1$).
Авторы указывают, что из-за специфики процесса разметки набор содержит мало примеров пар отрицательного класса.

Для решения поставленной задачи был выбран подход, предполагающий включение в корпус только вручную классифицированных пар, предварительно отобранных с использованием модели семантической близости предложений.
Так как корпус \mbox{<<Quora Question Pairs>>} успешно применяется для оценки качества моделей выявления парафраза на английском языке, было решено использовать аналогичный источник данных и структуру классов.

\section{Метод сбора данных}
\subsection{Сбор корпуса вопросов}
На русском языке существуют два крупнейших ресурса в сети Интернет, предоставляющих пользователям возможность публиковать свои и отвечать на чужие вопросы: \href{https://yandex.ru/q/}{\mbox{<<Yandex Q>>}} и \href{https://otvet.mail.ru/}{\mbox{<<Ответы Mail.ru>>}}.
Оба ресурса содержат большое количество вопросов, которые соответствуют критериям, предъявляемых к источнику текстов в рамках задачи.
Для выбора одного из них был проведен анализ пользовательских соглашений.

В пользовательском соглашении \mbox{<<Ответы Mail.ru>>}~\autocite{mail_legal} был указан прямой запрет на использование средств для автоматизации взаимодействия с ресурсом.\\
Правила пользования сервисом \mbox{<<Yandex Q>>}~\autocite{yandex_legal} в период, когда проводился сбор корпуса, подобного ограничения не содержали.
Более того, соглашение закрепляет за \mbox{ООО} \mbox{<<ЯНДЕКС>>} возможность предоставить право третьим лицам хранить и распространять размещенные пользователями материалы.

Поэтому в качестве источника для сбора данных был выбран сайт \mbox{<<Yandex Q>>}.
Так как соглашение об использовании сервиса сохраняет авторское право на публикуемые вопросы за разместившими их пользователями, то при решении поставленной задачи непосредственно тексты вопросов не сохранялись и не публиковались.
При необходимости провести анализ, текст каждый раз временно загружался со страницы вопроса.
На некоторых страницах портала явно указана одна или несколько тем, к которым относиться вопрос.
Эти темы не являются уникальным пользовательским материалом, поэтому собирались и сохранялись нами как дополнительная информация.

С помощью библиотеки \texttt{Scrapy}~\autocite{scrapy_docs} на языке \mbox{Python} рекурсивно обходились страницы сайта.
Когда посещалась страница, содержащая вопрос, сохранялась ссылка на нее и темы, ассоциированные с вопросом.
Данные сохранялись в \mbox{SQL} базу данных.
Идентификатор полученной записи использовался как уникальный номер соответствующего вопроса на всех этапах дальнейшей обработки.

Ссылки собирались непрерывно в течении $19$ дней.
Всего было собрано $267\,640$ ссылок на вопросы.
$248\,278$ из них относились к определенной теме.

\subsection{Отбор кандидатов на разметку}
Ручная разметка всех возможных пар такого объемного корпуса не представлялась возможной в рамках данной работы.
Поэтому для дальнейшей разметки были отобраны лишь некоторые пары вопросов.

В первую очередь в корпусе были оставлены только вопросы, тексты которых соответствовали следующим критериям:
\begin{itemize}
    \item Содержит только символы \mbox{ASCII} или кириллические символы \mbox{Unicode}
    \item Не содержит обсценных слов
    \item В тексте не встречаются слишком редкие слова (имеющие статистику ${\mathrm{IPM} < 2}$ по частотному словарю~\autocite{ляшевская2009частотный})
    \item Состоит не менее чем из $6$ слов
    \item Состоит не более чем из $12$ слов
\end{itemize}

На последней стадии отбора пар-кандидатов были получены векторные представления всех предложений с использованием модели \mbox{SentenceBERT}~\autocite{reimers2019sentence}, предварительно обученной на корпусе русского языка лабораторией \mbox{DeepPavlov}~\autocite{deeppavlov_sbert}.
Данная модель обучалась авторами таким образом, чтобы для схожих по смыслу предложений их векторные представления имели большое значение косинусной близости.

При ручной разметке небольшого числа случайно выбранных пар не было обнаружено парафразов, у которых векторные представления имели близость ниже $0.9$.
При этом в группе с большим значением близости доля парафразов была примерно равна $0.2$.
Можно заключить, что современные предварительно обученные языковые модели способны выявлять близкие по смыслу предложения без дополнительного обучения под конкретную задачу.
Однако для таких моделей может быть затруднительно определить пары предложений, состоящих из похожих слов и близких синтаксически, но разных по смыслу.

Для дальнейшей разметки были выбраны пары, у которых косинусная близость между полученными векторами оказалась не меньше $0.9$.

\subsection{Разметка отобранных пар}
Для получения метки класса было составлено задание на краудсорсинговой платформе \href{https://toloka.yandex.ru/}{\mbox{<<Яндекс Толока>>}}.
Платформа предоставляет возможность получить решение набора специально оформленных, обычно простых, заданий.
Задания доступны для выполнения на возмездной основе большому числу пользователей.

Исполнителям предлагалось проследовать по двум гиперссылкам, указывающим на страницы вопросов, и дать ответ являются ли два вопроса одинаковыми по смыслу.
Каждая пара была размечена как минимум $3$ разными исполнителями.

Для улучшения качества итоговой разметки были использованы несколько способов контроля, доступных на платформе.
Наиболее важными из них были: обязательное прохождение обучения перед выполнением заданий и контрольные вопросы.\\
Обучение представляло собой набор характерных пар с известными метками класса.
Если исполнитель давал неверный ответ на задание, ему демонстрировался подробный комментарий, аргументирующий выбор правильного ответа.

Контрольные вопросы — задания, для которых известен правильный ответ, но неотличимые для исполнителя от обычного задания.
Было решено сделать $20\%$ всех заданий контрольными.
Для составления коллекции необходимого размера была применена следующая процедура:
\begin{enumerate}
    \item Нами собственноручно было размечено $100$ контрольных заданий.
    \item Была получена разметка для $500$ пар.
    \item Отобраны $300$ пар с наибольшей согласованностью ответов исполнителей, с помощью модели~\autocite{dawid1979maximum}, доступной на платформе.
    \item Эти пары вместе с исходными были использованы для составления контрольных заданий. 
\end{enumerate}

В рамках доступного бюджета удалось получить разметку для $1915$ пар.\\
Валидационная выборка опубликована~\footnote{\url{https://github.com/wosadeh/Russian-Question-Pairs/raw/9b23240454356d1aaadf81a55f5b2847dec0b415/dev.tsv}} в открытом доступе.
\begin{table}[htbp]
    \caption{Пример итоговой разметки пар}
    \label{table:data_sample}
    \footnotesize
    \centering
    \begin{tabular}{ | c | p{5cm} | c | p{5cm} | c |}
        \hline
        \textbf{left\_id} &\multicolumn{1}{c|}{\textbf{left\_url}}
        &\textbf{right\_id} & \multicolumn{1}{c|}{\textbf{right\_url}}
        &\textbf{class}\\
        \hline
        $60130$
        &\url{https://yandex.ru/q/question/business/kakie_dokumenty_nuzhny_dlia_prodleniia_60766740/}
        &$243915$
        &\url{https://yandex.ru/q/question/kakie_dokumenty_nuzhny_dlia_polucheniia_c208b2c3/}
        &$0$
        \\
        $73372$
        &\url{https://yandex.ru/q/question/kakaia_samaia_smeshnaia_kniga_kotoruiu_vy_1d1f4408/}
        &$93744$
        &\url{https://yandex.ru/q/question/kakuiu_samuiu_smeshnuiu_knigu_vy_chitali_1bfd9c12/}
        &$1$
        \\
        $28539$
        &\url{https://yandex.ru/q/question/transport/kak_chasto_nuzhno_meniat_vozdushnyi_filtr_f0c703a3/}
        &$66554$
        &\url{https://yandex.ru/q/question/transport/kak_chasto_nado_meniat_tormoznuiu_b7acdca5/}
        &$0$
        \\
        \hline
    \end{tabular}
\end{table}

\section{Анализ собранных данных}
Количество размеченных пар получилось существенно меньше, чем у аналогичных наборов, рассмотренных ранее.
Так как изначально была поставлена задача создания набора данных для оценки качества и сравнение предварительно обученных языковых моделей, то было решено исследовать возможность применения собранных данных только в виде тестовой и валидационной выборки.

Для получения итоговой метки классов из ответов нескольких исполнителей применялась модель~\autocite{dawid1979maximum}, использующая \mbox{EM}-алгоритм для максимизации правдоподобия итоговой разметки.
Данная модель помимо самой метки оценивает уверенность в агрегированном значении.
Из набора были исключены размеченные пары вопросов, уверенность на которых была ниже $92\%$.

В тестовую выборку были включены по $300$ примеров отрицательного и положительного класса с уверенностью в метке не менее $99\%$.\\
В валидационную выборку вошли все остальные пары вопросов.
\subsection{Описание данных}
Для обеих выборок была вычислена мера~\autocite{fleiss1971measuring} межэкспертной надежности полученной разметки.
Чтобы иметь представление о сложности текстов, были вычислены статистики: метрика \mbox{MTLD}~\autocite{mccarthy2010mtld} лексического разнообразия, среднее количество слов в вопросе, разница в длине между вопросами в одной паре.
Также с помощью библиотеки \texttt{pymorphy2}~\autocite{pymorphy2} были выявлены некоторые морфологические свойства текстов.
Данные представлены в таблице~\ref{table:set_stats}.\\
\begin{table}[htbp]
    \caption{Описательные статистики}
    \label{table:set_stats}
    \footnotesize
    \centering
    \begin{tabular}{ | >{\bfseries}m{8cm} | c c |}
        \hline
        \diagbox[innerwidth=8cm]{Статистика}{Подвыборка}& Тестовая & Валидационная\\
        \hline
        Размер & $600$ & $1121$\\
        Доля примеров положительного класса & $0.5$ & $0.24$\\
        \hline
        Межэкспертная надежность & $0.77$ & $0.63$\\
        \hline
        MTLD & $25.1$ &$31.9$\\
        Среднее количество слов в вопросе & $8.03$ & $8.09$\\
        Средняя разница количества слов в паре вопросов & $1.3$ & $1.4$\\
        Доля пар, содержащих числа & $0.115$ & $0.145$\\
        Доля пар, содержащих деепричастие & $0.031$ & $0.032$\\
        Доля пар, содержащих отрицание & $0.085$ & $0.105$\\
        \hline
    \end{tabular}
\end{table}
Так как при разметке использовались контрольные задания, то для них возможно посчитать среднюю долю верных ответов.
Эту величину, равную $84.34\%$, можно рассматривать как приблизительную оценку качества определения парафраза людьми в примерах из нашего корпуса. 

Полученные значения для межэкспертной надежности свидетельствуют о высокой согласованности ответов исполнителей для пар, вошедших в итоговые выборки.\\
В двух подвыборках значительно отличаются доли положительных пар.
Преимущество сбалансированной тестовой выборки состоит в более показательной оценке при использовании некоторых метрик качества, чувствительных к балансу классов.
Несбалансированная валидационная выборка позволяет использовать большее количество размеченных данных.
Это различие также проявляется и в большем значении метрики \mbox{MTLD}.

Остальные рассмотренные статистики имеют близкое значение у обеих выборок.

\subsection{Тестирование моделей}
    Чтобы оценить качество языковых моделей на полученной тестовой выборке были рассмотрены несколько техник переноса обучения с других наборов данных, схожих с полученным нами.
\tocless\subsubsection{Paraphraser}\label{sssec:paraphraser}
    В первом эксперименте была использована предварительно обученная для русского языка модель \mbox{RuBERT}~\autocite{kuratov2019adaptation}.
    Архитектура \mbox{BERT}, на которой она основана, изначально поддерживает обработку пары предложений, разделенных специальным токеном \texttt{[SEP]}.
    Контекстуальное векторное представление специального токена \texttt{[CLS]} передавалось на вход двухслойной полносвязной нейросети для классификации.
    
    Для обучения использовался набор данных \mbox{<<Paraphraser>>}~\autocite{pivovarova2017paraphraser}. В этом корпусе пары предложений разделены на $3$ класса. Для обучения модели бинарной классификации использовалась кросс-энтропийная функция потерь.
    \begin{equation}
        \mathcal{L}(p, y) = -q_{y}\log{(p)} - (1 - q_{y}) \log{(1 - p)}
    \end{equation}
    Где $p$ -- возвращаемая моделью вероятность положительного класса, $y$ -- метка класса для пары предложений. $q_y$ выбрана равным $1$ для <<точного парафраза>>, $0$ для пар различных предложений и равным $0.5$ для частично совпадающих по смыслу пар.
    
    В качестве оптимизатора использовался \mbox{Adam}~\autocite{kingma2014adam} c параметрами ${\beta_1 = 0.9}$, ${\beta_2 = 0.999}$, скоростью обучения $5 \cdot 10^{-5}$, размером пакета равным $32$.\\
    В процессе обучения обновлялись веса только двух последних слоев \mbox{BERT} и полносвязные слои для классификации.\\
    Обучение продолжалось $10$ эпох.
    После каждой эпохи обучения с использованием валидационной выборки вычислялось значение метрики Accuracy. В качестве итоговой выбиралась промежуточная модель с наибольшим значением метрики.
    
\tocless\subsubsection{Перевод QQP}\label{sssec:transl_qqp}
    Во втором эксперименте обучающие данные были получены с помощью машинного перевода языка корпуса \mbox{<<QQP>>}~\autocite{iyer_csernai_dandekar_2017}.
    Для перевода использовалась предварительно обученная модель \mbox{FairSeq}~\autocite{ng2019facebook}.
    
    Данная модель продемонстрировала~\autocite{wmt19findings} хорошее качество перевода с английского языка на русский как по метрике \mbox{BLEU}, так и по данной людьми оценке. Пример переведенных предложений приведен в таблице~\ref{table:qqp_tr_ex}.
    \begin{table}[htbp]
        \caption{Пример перевода}
        \label{table:qqp_tr_ex}
        \footnotesize
        \centering
        \begin{tabular}{ | p{8cm} | p{8cm} |}
            \hline
            \textbf{Исходное предложение} & \textbf{Русский перевод}\\
            \hline
            What is the step by step guide to invest in share market in india?
            &
            Каково пошаговое руководство по инвестированию в рынок акций в Индии?\\
            \hline
            What are some examples of deuteromycota and how are they formed?
            &
            Каковы некоторые примеры теромикоты и как они формируются?\\
            \hline
            How light bend with gravity?
            &
            Как легко согнуть с гравитацией?\\
            \hline
        \end{tabular}
    \end{table}
    
    Используемая предобученная модель, архитектура и оптимизатор аналогичны прошлому эксперименту.
    В качестве функции потерь использовалась стандартная кросс-энтропия.
    Обучение длилось $3$ эпохи.
\tocless\subsubsection{LaBSE}\label{sssec:labse_qqp}
    Последний эксперимент проводился с другой предварительно обученной моделью \mbox{LaBSE}~\autocite{feng2020language} имеющей сходную с \mbox{BERT} архитектуру.
    Данная мультиязычная модель обучалась авторами таким образом, чтобы предложения со схожим смыслом имели близкие (в плане косинусного расстояния) векторные представления для \texttt{[CLS]}.
    
    Для классификации пары предложений векторные представления токена \texttt{[CLS]} конкатенировались и подавались на вход полносвязной нейросети с двумя слоями.\\
    Дополнительно, чтобы сохранить свойство исходной модели, для пар положительного класса в функцию ошибки было добавлено слагаемое, отвечающее косинусной близости векторных представлений.
    Функция потерь имела следующий вид:
    \begin{equation}
    \mathcal{L}(v_0, v_1, y) = -\log{f_y{(v_0, v_1)}} + \lambda \cdot y\left( 1 - \phi{(v_0, v_1)} \right)
    \end{equation}
    где $y$ -- метка класса, $v_0$, $v_1$ -- векторные представления \texttt{[CLS]} токена для первого и второго предложения соответственно, $f_y{(v_0, v_1)}$ -- выход последнего слоя нейросети для класса $y$, $\phi$ -- косинусная близость двух векторов.
    
    В эксперименте использовалась обучающая выборка \mbox{<<QQP>>}~\autocite{iyer_csernai_dandekar_2017} на английском языке.
    Гиперпараметр $\lambda$ выбран равным $0.1$.
    Обучение продолжалось $3$ эпохи с помощью оптимизатора \mbox{Adam}~\autocite{kingma2014adam} c параметрами ${\beta_1 = 0.9}$, ${\beta_2 = 0.999}$, $\mathrm{learning\_rate} = {10}^{-5}$, коэффициентом {L2} регуляризации равным ${10}^{-2}$ и пакетом размера $32$.
 
\tocless\subsubsection{Результаты}
    Каждый эксперимент повторялся $5$ раз с различными инициализациями генератора псевдослучайных чисел.
    Как следствие в каждом запуске различались начальные веса последних слоев нейросетей и порядок обхода объектов выборки при стохастической оптимизации.
    
    После обучения были вычислены метрики качества на тестовой выборке.
    Средние значения ($\mu$) и стандартные отклонения ($\sigma$) приведены в таблице~\ref{table:run_res}.
    \begin{table}[htbp]
        \caption{Результаты тестирования}
        \label{table:run_res}
        \footnotesize
        \centering
        \begin{tabular}{ | c | c  c | c  c | c  c | }
            \hline
            Эксперимент & \multicolumn{2}{c|}{Accuracy} & \multicolumn{2}{c|}{F1} & \multicolumn{2}{c|}{ROC-AUC}\\
            \cline{2-7}
            &$\mu$&$\sigma$&$\mu$&$\sigma$&$\mu$&$\sigma$\\
            \hline
            Paraphraser + RuBERT
            &$74.17$ & $01.28$
            &$72.93$ & $02.81$
            &$82.90$ & $01.72$\\
            \hline
            FairSeq EN-RU + QQP + RuBERT
            &$79.10$ & $02.12$
            &$78.98$ & $02.23$
            &$86.98$ & $01.24$\\
            \hline
            \makecell{ --- \raisebox{-0.5ex}{''} --- \\ (сбалансированная вал. выборка) }
            &$79.70$ & $01.05$
            &$79.35$ & $01.70$
            &$87.20$ & $00.66$\\
            \hline
            QQP + LaBSE
            &$75.77$ & $01.79$
            &$76.76$ & $02.19$
            &$83.81$ & $01.45$\\
            \specialrule{.25em}{.1em}{.1em}
            RuBERT + Paraphraser (тест)~\autocite{kuratov2019adaptation}
            &$84.99$ &$00.35$
            &$87.73$ &$00.26$
            &---&---\\
            \hline
            BERT + QQP (тест)~\autocite{devlin2018bert}
            &$89.30$&---
            &$71.20$ &---
            &---&---\\
            \hline
        \end{tabular}
    \end{table}

    При использовании корпуса \mbox{<<Paraphraser>>}~\autocite{pivovarova2017paraphraser} в качестве обучающей выборки значения метрик Accuracy и \mbox{F1} получились значительно ниже, чем удалось достичь авторам той же модели на тестовой выборке из этого корпуса.
    Это можно объяснить тем, что этот корпус значительно отличается от собранного нами как по источнику текстов, так и по структуре классов.
    
    При использовании для обучения набора данных \mbox{<<QQP>>}~\autocite{iyer_csernai_dandekar_2017} значение всех метрик качеств получилось значительно лучше.
    Достигнутая в наших экспериментах величина F1 не сильно отличается по значению от полученной~\autocite{devlin2018bert} авторами модели \mbox{BERT} для тестовой выборки \mbox{<<QQP>>}.
    Все это может свидетельствовать о том, что полученный нами набор данных действительно имеет сходство с аналогом на английском языке.
    
    Второй эксперимент был также повторен с использованием подмножества валидационной выборки с равной долей примеров обоих классов.
    Значение метрик качества оказалось выше, а их разброс меньше.
    Разница оказалась не слишком велика, так как валидационная выборка использовалась исключительно для отбора лучшей из промежуточных моделей во время обучения.
    Тем не менее важно учитывать, что использование сбалансированного подмножества валидационной выборки может улучшить значение метрик качества на тестовой выборке.
    
    Значения имеют больший разброс, чем полученные в схожих экспериментах авторами русскоязычной модели~\autocite{kuratov2019adaptation}.
    Скорее всего причиной послужил небольшой по сравнению с аналогами объем полученного корпуса и использование техник переноса обучения.\\
    Значение метрик Accuracy и F1 в наших экспериментах имеют близкие значения, так как в тестовой выборке доли пар обоих классов равны.
    
    Из данных экспериментов видно, что в каждом из них примерно каждая пятая пара классифицируется моделью неверно.
    Возможно причина состоит в том, что на этапе отбора кандидатов на разметку выбирались те пары предложений, которые определялись \mbox{SentenceBERT} моделью как семантически близкие, при том что большая часть из них в итоге не была размечена людьми как парафраз.
    Такие примеры являются априори сложными для правильной классификации моделями из семейства \mbox{BERT}.
\begin{comment}
    Это предположение косвенно подтверждается тем, что в ряде экспериментов значение метрики Accuracy на тестовой выборке было больше, чем на валидационной, в которой больше доля примеров отрицательного класса.
\end{comment}
    Из описательных статистик для выборок видно, что примерно каждая десятая пара содержит числа или отрицание.
    Автоматический анализ подобных предложений также может быть затруднительным.
    
    Можно сделать вывод, что полученный корпус возможно использовать для оценки качества обнаружения парафраза предварительно обученными моделями.
    Однако полученная оценка будет значительно зависеть от выбранной техники переноса обучения.
    Поэтому для корректного сравнения различных моделей необходимо зафиксировать такую технику или дополнить полученный корпус обучающей выборкой в рамках дальнейших исследований.
    
    Исходный код программ, использованных для сбора, обработки данных и проведения экспериментов, доступен в репозитории\footnote{\url{https://github.com/wosadeh/Russian-Question-Pairs}}.
\section{Заключение}
В рамках работы был создан корпус коротких вопросов-парафразов на русском языке.
Полученный набор данных отличается от существующих аналогов для русского языка.

Отобранные выборки данных возможно использовать для оценки качества обнаружения парафраза современными языковыми моделями при применении техник переноса обучения.
Однако полученные при таком подходе значения метрик качества будут сильно зависеть от использованной техники.

Поэтому в рамках дальнейших исследований целесообразно разметить оставшиеся пары-кандидаты и выделить из них полноценную обучающую выборку.

Также возможно значительно улучшить формат представления данных, если получить согласие представителей сервиса \mbox{<<Yandex Q>>} на публикацию текстов вопросов.

\addcontentsline{toc}{section}{Список литературы}
\printbibliography[title={Список литературы (или источников)}]
\end{document}
