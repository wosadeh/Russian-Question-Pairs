\documentclass[a4paper,14pt]{extarticle}
\usepackage{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{indentfirst}
\usepackage[colorlinks,citecolor=blue,linkcolor=blue,bookmarks=false,hypertexnames=true, urlcolor=blue]{hyperref} 
\usepackage{indentfirst}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage[flushleft]{threeparttable}
\usepackage{tablefootnote}
\usepackage{csquotes}
\usepackage{comment}

\usepackage{chngcntr} % нумерация графиков и таблиц по секциям
\counterwithin{table}{section}
\counterwithin{figure}{section}

% \graphicspath{{graphics/}}%путь к рисункам

\makeatletter
% \renewcommand{\@biblabel}[1]{#1.} % Заменяем библиографию с квадратных скобок на точку:
\makeatother

\geometry{left=2.5cm}% левое поле
\geometry{right=1.5cm}% правое поле
\geometry{top=1.5cm}% верхнее поле
\geometry{bottom=1.5cm}% нижнее поле
\renewcommand{\baselinestretch}{1.5} % междустрочный интервал


% \newcommand{\bibref}[3]{\hyperlink{#1}{#2 (#3)}} % biblabel, authors, year
% \addto\captionsrussian{\def\refname{Список литературы (или источников)}} 

\renewcommand{\theenumi}{\arabic{enumi}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumi}{\arabic{enumi}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\theenumii}{.\arabic{enumii}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}.}% Меняем везде перечисления на цифра.цифра
\renewcommand{\theenumiii}{.\arabic{enumiii}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumiii}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.}% Меняем везде перечисления на цифра.цифра

% Подключаем BibLaTex
\usepackage[%
backend=biber,% движок
bibencoding=utf8,% кодировка bib файла
sorting=none,% настройка сортировки списка литературы
style=gost-numeric,% стиль цитирования и библиографии (по ГОСТ)
language=autobib,% получение языка из babel/polyglossia, default: autobib % если ставить autocite или auto, то цитаты в тексте с указанием страницы, получат указание страницы на языке оригинала
autolang=other,% многоязычная библиография
clearlang=true,% внутренний сброс поля language, если он совпадает с языком из babel/polyglossia
defernumbers=true,% нумерация проставляется после двух компиляций, зато позволяет выцеплять библиографию по ключевым словам и нумеровать не из большего списка
sortcites=true,% сортировать номера затекстовых ссылок при цитировании (если в квадратных скобках несколько ссылок, то отображаться будут отсортированно, а не абы как)
doi=false,% Показывать или нет ссылки на DOI
isbn=false,% Показывать или нет ISBN, ISSN, ISRN
movenames=false, % Не заменяем авторов названием, если у публикации более 3 авторов
]{biblatex}
\addbibresource{sources.bib}

\begin{document}
\input{title.tex}% титульный лист
\newpage

{
	\hypersetup{linkcolor=black}
	\tableofcontents
}

\newpage
\addcontentsline{toc}{section}{Аннотация}
\begin{abstract}
    В последние несколько лет предварительно обученные нейросетевые языковые модели находят все большее применение в различных задачах обработки естественного языка.
    Для оценки таких моделей на русском языке активно разрабатывается бенчмарк RussianSuperGLUE.
    В рамках данной работы решается задача создания набора коротких вопросов-парафразов на русском языке для расширения набора заданий бенчмарка.
\end{abstract}
\textbf{\textit{Ключевые слова---}} Детекция парафраза, обработка естественного языка, GLUE, разработка датасета, QQP

\selectlanguage{english}
\begin{abstract}
    Pretrained neural language models find broad application in various tasks of natural language processing.
    RussianSuperGLUE benchmark offers a metric to measure and compare a quality of such models.
    In this paper we present a question paraphrase pairs dataset in Russian that can be used as new benchmark task.
\end{abstract}
\textbf{\textit{Keywords---}} Paraphrase detection, NLP, GLUE, dataset development, QQP

\selectlanguage{russian}

\newpage

\section{Введение}
\subsection{Описание предметной области}

Бенчмарк в контексте машинного обучения — набор заданий, позволяющих оценить качество модели. Каждое задание соответствует конкретной задаче машинного обучения и представлено выборкой данных, характерных для данной задачи. Для каждого задания определена метрика качества.

Для задач обработки текстов на английском языке существует большое количество бенчмарков.
GLUE~\autocite{wang2018glue} содержит набор заданий, которые позволяют оценить общее понимание естественного языка моделью. Данная оценка наиболее актуальна для современных моделей на основе архитектуры <<Трансформер>>, которые демонстрируют впечатляющие результаты во многих задачах обработки естественного языка.

Однако, качество решения предложенных задач новейшими языковыми моделями вплотную приближается или даже превышает результат, демонстрируемый человеком.
Бенчмарк SuperGLUE~\autocite{wang2019superglue} предлагает набор более сложных и разнообразных заданий.

Аналогичный подход к оценке качества языковых моделей для русского языка реализует бенчмарк RussianSuperGLUE~\autocite{shavrina2020russiansuperglue}.
На данный момент бенчмарк содержит заметно меньшее число заданий, чем два вышеописанных.
Поэтому существует необходимость добавления новых заданий.

\subsection{Постановка задачи}

В работе была поставлена задача создания набора данных с парами вопросов-парафразов на русском языке по аналогии с заданием на английском языке {<<Quora Question Pairs>>}~\autocite{iyer_csernai_dandekar_2017}.

Набор данных должен состоять из пар предложений. Каждой паре необходимо сопоставить категориальную метку, показывающую имеют ли предложения одинаковый смысл.
Предложения должны представлять собой вопросы, размещенные пользователями в сети Интернет на русскоязычном аналоге платформы \href{https://www.quora.com/}{Quora.com}.
Сопоставление каждой паре соответствующей метки должно производится с использованием краудсорнинговой платформы, предлагающей услуги ручной разметки данных.

Полученное множество необходимо разделить на обучающую и тестовую выборку.
Для оценки полученных результатов необходимо исследовать возможность использование полученного корпуса для обучения современных моделей, сравнить объем и содержание корпуса с существующими аналогами.

\section{Обзор литературы}

Задача обнаружения парафраза между парой документов является распространенной задачей анализа естественного языка.
Как следствие существуют несколько наборов данных, содержащих пары семантически близких документов, различающихся по размеру, специфике текстов и подходу к сбору и разметке данных.

Наиболее объемные наборы получены с помощью автоматического составления парафразов.
В~\autocite{ganitkevitch2013ppdb} представлен корпус из $230$ миллионов пар на английском языке, полученный с использованием моделей семантической близости предложений.
Набор~\autocite{wieting2017paranmt} из $50$ миллионов пар был создан из параллельного корпуса текстов на английском и чешском языках с помощью предварительно обученной нейросетевой модели машинного перевода текстов.
Хотя процесс автоматической разметки данных может приводить к появлению ошибок в полученных парах, авторы демонстрируют, что полученные наборы могут успешно применяться для обучения моделей обнаружения парафразов.

Однако подобные наборы данных не подходят для оценки качества языковых моделей, так как они содержат некорректные пары. Как следствие полученное значение точности не будет отражать реальное качество модели.
Поэтому для оценки и сравнения моделей выявления парафраза обычно используют вручную размеченные данные.
Наиболее популярным является корпус~\autocite{iyer_csernai_dandekar_2017}, составленный из пар вопросов, опубликованных пользователями сайта \href{https://www.quora.com/}{Quora.com} и размеченный вручную.
Несмотря на то, что авторы не публикуют подробную методику составления корпуса и признают возможность наличия ошибок в нем, этот набор данных успешно применяется для оценки качества моделей.

При совместном использовании ручной разметки и моделей машинного обучения итоговый корпус получается значительно большего размера в сравнении с исключительно ручной разметкой и содержит меньше ошибок, чем набор данных, составленный автоматически.
Составители набора {<<Language-Net>>}~\autocite{lan-etal-2017-continuously} демонстрируют, что модель, обученная на вручную размеченном наборе данных, позволяет в дальнейшем непрерывно отбирать новые пары-кандидаты с точностью близкой к $70\%$.

В работе~\autocite{zhang2019paws} был предложен подход к расширению существующего корпуса парафразов за счет генерирования новых пар, полученных путем перестановки слов в исходных предложениях. Авторами был сделан вывод о невысокой точности данного способа из-за чувствительности предложений на английском языке к изменению порядка слов. Однако данный подход может оказаться более эффективным при применении к корпусу на русском языке, в котором перестановка слов менее выражено изменяет смысл предложения.

Один из немногих корпусов парафраза на русском языке~\autocite{pivovarova2017paraphraser} является полностью размеченным вручную. Предложения в корпусе получены из заголовков публикаций российских новостных агентств.
Для отбора пар-кандидатов авторы используют собственную метрику близости предложений, что позволяет повысить эффективность дальнейшей ручной обработки. В отличие от ранее рассмотренных, в представленном наборе данных пары делятся на три класса: полностью совпадающие по смыслу ($1$), близкие по смыслу ($0$) и разные по смыслу ($-1$).
Авторы указывают, что из-за специфики процесса разметки набор содержит мало примеров пар отрицательного класса.

Для решения поставленной задачи был выбран подход, предполагающий включение в корпус только вручную классифицированных пар, предварительно отобранных с использованием модели семантической близости предложений.
Так как корпус {<<Quora Question Pairs>>} успешно применяется для оценки качества моделей выявления парафраза на английском языке, было решено использовать аналогичный источник данных и структуру классов.

\section{Метод сбора данных}

В качестве источника для сбора данных был выбран сайт \href{https://yandex.ru/q/}{<<Yandex Q>>} в сети Интернет, на котором публикуются вопросы пользователей на русском языке.
Так как правила пользования сервисом сохраняют авторское право на публикуемые вопросы за разместившими их пользователями, то при решении поставленной задачи непосредственно тексты вопросов не сохранялись и не публиковались. При необходимости провести анализ, текст временно загружался со страницы вопроса.

С помощью библиотеки Scrapy на языке Python рекурсивно обходились страницы сайта. Когда посещалась страница, содержащая вопрос, сохранялась ссылка на нее и темы, ассоциированные с вопросом.
Данные сохранялись в SQL базу данных. Идентификатор полученной записи использовался как уникальный номер соответствующего вопроса на всех этапах дальнейшей обработки.

Ссылки собирались непрерывно в течении $19$ дней. Всего было собрано $267\,640$ ссылок на вопросы. $248\,278$ из них относились к определенной теме.
Для дальнейшего использования были отобраны вопросы, текст которых соответствовали следующим критериям:
\begin{itemize}
    \item Содержит только символы ASCII или кириллические символы Unicode
    \item Не содержит обсценных слов
    \item В тексте не встречается слишком редких слов (чья статистика ${\mathrm{IPM} \ge 2}$ по частотному словарю~\autocite{ляшевская2009частотный})
    \item Состоит не менее чем из $6$ слов
    \item Состоит не более чем из $12$ слов
\end{itemize}

Для отбора пар-кандидатов были получены векторные представления всех предложений с использованием модели~\autocite{reimers2019sentence}, предварительно обученной на корпусе русского языка лабораторией DeepPavlov.
Для дальнейшей разметки были выбраны пары, у которых косинусная близость между полученными векторами оказалась больше заранее выбранного порога.
Для оценки качества отбора кандидатов планируется построить диаграмму калибровки модели на основе небольшого количества размеченных пар с разной величиной косинусной близости.


Для получения метки класса было составлено задание на краудсорсинговой платформе \href{https://toloka.yandex.ru/}{<<Яндекс Толока>>}.
В качестве элементов контроля качества работы пользователей, выполняющих разметку, каждая пара будет размечена $3$ разными пользователями, оценены ответы пользователей на контрольных заданиях, введены ограничения для пользователей, отвечающих слишком быстро.

% Эта структура кажется слишком подробной для плана
\begin{comment}
\subsection{Выбор источника}

На русском языке существуют два крупнейших ресурса в сети Интернет, предоставляющих пользователям возможность публиковать свои и отвечать на чужие вопросы: \href{https://yandex.ru/q/}{<<Yandex Q>>} и \href{https://otvet.mail.ru/}{<<Ответы Mail.ru>>}.
Оба ресурса содержат большое количество вопросов, которые соответствуют критериям, предъявляемых к источнику предложений для решаемой задачи.
Для выбора одного из них был проведен анализ пользовательского соглашения и веб интерфейса.


\subsection{Сбор данных}
\subsection{Предварительная фильтрация}
\subsection{Отбор кандидатов на ручную классификацию}
\subsection{Ручная разметка данных}
\end{comment}

\section{Анализ собранных данных}

После агрегации ответов с <<Яндекс Толоки>>, будет проведен анализ содержания и размера полученного корпуса и составлено его описание.

Для изучения возможности практического применения полученного корпуса будет дообучена модель~\autocite{devlin2018bert} на обучающей подвыборке и измерена точность на тестовой выборке.
Ожидается, что качество обученной модели будет сравнимо с качеством, достигаемым при использовании существующих корпусов парафраза.

\printbibliography

\end{document}
