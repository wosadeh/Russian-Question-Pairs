% !TeX spellcheck = ru_RU
\documentclass[a4paper,14pt]{extarticle}
\usepackage{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{indentfirst}
\usepackage[colorlinks,citecolor=blue,linkcolor=blue,bookmarks=false,hypertexnames=true, urlcolor=blue]{hyperref} 
\usepackage{indentfirst}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage[flushleft]{threeparttable}
\usepackage{tablefootnote}
\usepackage{csquotes}

\usepackage{chngcntr} % нумерация графиков и таблиц по секциям
\counterwithin{table}{section}
\counterwithin{figure}{section}

% \graphicspath{{graphics/}}%путь к рисункам

\makeatletter
% \renewcommand{\@biblabel}[1]{#1.} % Заменяем библиографию с квадратных скобок на точку:
\makeatother

\geometry{left=2.5cm}% левое поле
\geometry{right=1.5cm}% правое поле
\geometry{top=1.5cm}% верхнее поле
\geometry{bottom=1.5cm}% нижнее поле
\renewcommand{\baselinestretch}{1.5} % междустрочный интервал


% \newcommand{\bibref}[3]{\hyperlink{#1}{#2 (#3)}} % biblabel, authors, year
% \addto\captionsrussian{\def\refname{Список литературы (или источников)}} 

\renewcommand{\theenumi}{\arabic{enumi}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumi}{\arabic{enumi}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\theenumii}{.\arabic{enumii}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}.}% Меняем везде перечисления на цифра.цифра
\renewcommand{\theenumiii}{.\arabic{enumiii}}% Меняем везде перечисления на цифра.цифра
\renewcommand{\labelenumiii}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.}% Меняем везде перечисления на цифра.цифра

% Подключаем BibLaTex
\usepackage[%
backend=biber,% движок
bibencoding=utf8,% кодировка bib файла
sorting=none,% настройка сортировки списка литературы
style=gost-authoryear,% стиль цитирования и библиографии (по ГОСТ)
language=autobib,% получение языка из babel/polyglossia, default: autobib % если ставить autocite или auto, то цитаты в тексте с указанием страницы, получат указание страницы на языке оригинала
autolang=other,% многоязычная библиография
clearlang=true,% внутренний сброс поля language, если он совпадает с языком из babel/polyglossia
defernumbers=true,% нумерация проставляется после двух компиляций, зато позволяет выцеплять библиографию по ключевым словам и нумеровать не из большего списка
sortcites=true,% сортировать номера затекстовых ссылок при цитировании (если в квадратных скобках несколько ссылок, то отображаться будут отсортированно, а не абы как)
doi=false,% Показывать или нет ссылки на DOI
isbn=false,% Показывать или нет ISBN, ISSN, ISRN
movenames=false, % Не заменяем авторов названием, если у публикации более 3 авторов
]{biblatex}
\addbibresource{sources.bib}

\begin{document}
\input{title.tex}% титульный лист
\newpage

{
	\hypersetup{linkcolor=black}
	\tableofcontents
}

\newpage
\section{Аннотация}
\newpage

\section{Введение}
\subsection{Описание предметной области}

Бенчмарк в контексте машинного обучения -- набор заданий, позволяющих оценить качество модели. Каждое задание соответствует конкретной задачи машинного обучения и представлено выборкой данных, характерных для данной задачи. Для каждого задания определена метрика качества.

Для задач обработки текстов на английском языке существует большое количество бенчмарков.
GLUE ~\autocite{wang2018glue} содержит набор заданий, которые позволяют оценить общее понимание языка моделью. Данная оценка наиболее актуальна для современных моделей на основе архитектуры <<Трансформер>>, которые демонстрируют впечатляющие результаты во многих задачах обработки естественного языка.

Однако, качество решения предложенных задач последними языковыми моделями вплотную приближается или даже превышает результат, демонстрируемый человеком.
Бенчмарк SuperGLUE ~\autocite{wang2019superglue} предлагает набор более сложных и разнообразных заданий.

Аналогичный подход к оценки качества языковых моделей для русского языка реализует бенчмарк Russian SuperGLUE ~\autocite{shavrina2020russiansuperglue}.
На данный момент данный бенчмарк содержит заметно меньшее число заданий, чем два вышеописанных.
Поэтому существует необходимость добавления новых заданий.

\subsection{Постановка задачи}

В работе была поставлена задача создания набора данных с парами вопросов-парафразов на русском языке по аналогии с заданием на английском языке {<<Quora Question Pairs>>}~\autocite{iyer_csernai_dandekar_2017}.

Набор данных должен состоять из пар предложений на русском языке. Каждой паре необходимо сопоставить категориальную метку, показывающую имеют ли предложения одинаковый смысл.
Предложения должны представлять из себя вопросы, размещенные пользователями в сети Интернет на русскоязычном аналоге платформы Quora.com . % TODO правильно офрмить ссылку на Quora.com
Сопоставление каждой паре соответствующей метки должно производится с использованием краудсорнинговой платформы, предлагающей услуги ручной разметки данных.

Полученное множество необходимо разделить на обучающую и тестовую выборку.
% TODO Добавить задачу анализа полученного датасета

\section{Обзор литературы}

Задача обнаружение парафраза между парой документов является распространенной задачей анализа естественного языка.
Как следствие существуют несколько наборов данных, содержащих пары семантически близких документов, различающихся по размеру, специфики текстов и подходу к сбору и разметки данных.

Наиболее объемные наборы получены с помощью автоматического составления пар парафразов.
В ~\autocite{ganitkevitch2013ppdb} представлен корпус из $230$ миллионов пар на английском языке, полученный с использованием моделей семантической близости предложений.
Набор ~\autocite{wieting2017paranmt} из $50$ миллионов пар был создан из параллельного корпуса текстов на английском и чешском языках с помощью предварительно обученной нейросетевой модели машинного перевода текстов.
Хотя процесс автоматической разметки данных может приводить к появлению ошибок в полученных парах, авторы демонстрируют, что полученные наборы могут успешно применяться для обучения моделей обнаружения парафразов.

Однако подобные наборы данных не подходят для использования при оценки качества языковых моделей, так как они содержат некорректные пары. Как следствие полученное значение метрики не будет отражать реальное качество модели.
Поэтому для оценки и сравнения моделей выявления парафраза обычно используют вручную размеченные данные.
Наиболее популярным является корпус ~\autocite{iyer_csernai_dandekar_2017}, составленный из пар вопросов, опубликованных пользователями сайта Quora.com и размеченный вручную.
Несмотря на то, что авторы не публикуют подробную методику составления корпуса и признают возможность наличия ошибок в данных, позволяет надежно оценить качество моделей.

При совместном использовании ручной разметки и моделей машинного обучения итоговый корпус получается значительно большего размера в сравнении с исключительно ручной разметкой и содержит меньше ошибок, чем набор данных, составленный автоматически.
Составители используемого для сравнения моделей набора {<<Language-Net>>}~\autocite{lan-etal-2017-continuously} демонстрируют, что модель обученная на вручную размеченном наборе данных позволяет в дальнейшем непрерывно отбирать новые пары-кандидаты с точностью близкой к $70\%$.

В работе ~\autocite{zhang2019paws} был предложен подход к расширению существующего корпуса парафразов за счет генерирования новых пар, полученных путем перестановки слов в исходных предложениях. Авторами был сделан вывод о невысокой точности данного способа из-за чувствительности предложений на английском языке к изменению порядка слов. Однако данный подход может оказаться более эффективным при применении к корпусу на русском языке, так как перестановка слов менее выражено изменяет смысл предложения на русском языке.

Один из немногих корпусов парафраза на русском языке ~\autocite{pivovarova2017paraphraser} является полностью размеченным вручную. Предложения в корпусе получены из заголовков российских новостных агентств.
Для отбора пар-кандидатов авторы используют собственную метрику близости предложений, что позволяет повысить эффективность дальнейшей ручной обработки. В отличии от ранее рассмотренных, в представленном наборе данных пары делятся на три класса: полностью совпадающие по смыслу ($1$), близкие по смыслу ($0$) и разные по смыслу ($-1$).
Авторы указывают, что из-за специфики процесса разметки набор содержит мало примеров пар отрицательного класса.

Для решения поставленной задачи был выбран подход, предполагающий включение в корпус только вручную классифицированных пар, предварительно отобранных с использованием модели семантической близости предложений.
Так как корпус {<<Quora Question Pairs>>} успешно применяется для оценки качества моделей выявления парафраза на английском языке, было решено использовать аналогичный источник данных и структуру классов.

\section{Метод сбора данных}
\subsection{Выбор источника}

На русском языке существуют два крупнейших ресурса в сети Интернет, предоставляющих пользователям возможность публиковать свои и отвечать на чужие вопросы: \href{https://yandex.ru/q/}{<<Yandex Q>>} и \href{https://otvet.mail.ru/}{<<Ответы Mail.ru>>}.
Оба ресурса содержат большое количество вопросов, которые соответствуют критериям, предъявляемых к источнику предложений для решаемой задачи.
Для выбора одного из них был проведен анализ пользовательского соглашения и веб интерфейса.

% TODO finish choice

\subsection{Сбор данных}
% TODO fill subsection
\subsection{Предварительная фильтрация}
% TODO fill subsection
\subsection{Отбор кандидатов на ручную классификацию}
% TODO fill subsection
\subsection{Ручная разметка данных}

\section{Анализ собранных данных}

\newpage 
\printbibliography

\end{document}
